{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ac96fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#below classes we used to interact with any llm model\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "\n",
    "#to convert the simple user query to Prompt we are using Chatprompttemplate,prompttemplate\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "\n",
    "#parser classes to parser \n",
    "from langchain_core.output_parsers import StrOutputParser,PydanticOutputParser\n",
    "\n",
    "#loading the env filter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import ToolMessage,AIMessage,HumanMessage,SystemMessage\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a94c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an object of chatGroq class\n",
    "model1 = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",temperature=0 #temperature is called creative parameter\n",
    ")\n",
    "\n",
    "#creating an object openai model class\n",
    "model2 = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",temperature=0\n",
    ")\n",
    "\n",
    "#creating an object open source model.\n",
    "#HuggingFaceEndpoint is a class where we are sending or hitting user query request to get response\n",
    "llm = HuggingFaceEndpoint(  \n",
    "        repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",  \n",
    "        task=\"text-generation\",  \n",
    "        )  \n",
    "model3 = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4355ef",
   "metadata": {},
   "source": [
    "Each message can be supplied with a few things:\n",
    "\n",
    "content - content of the message\n",
    "name - optionally, a message author\n",
    "response_metadata - optionally, a dict of metadata (e.g., often populated by model provider for AIMessages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5dafbb",
   "metadata": {},
   "source": [
    "# below is the kind of few shot prompting technique where we give  LLM model chat history with example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d8840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: user\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: user\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "#creating a list of messages holding/storing human and ai message init.\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"user\"))\n",
    "\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"user\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe307abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now passing the few shot prompting to llm chat model to give reposne based on context of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71344cfa",
   "metadata": {},
   "source": [
    "# chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ccd04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The best place to see Orcas (also known as killer whales) in the US is in the Pacific Northwest, particularly in the waters around Washington state and British Columbia, Canada. \\n\\nSome popular locations for orca sightings include:\\n\\n1. **Puget Sound**: Specifically, the San Juan Islands, which are located between the mainland and Vancouver Island. This area is home to the Southern Resident orcas, a distinct population of orcas that feed on salmon.\\n2. **San Juan Islands National Wildlife Refuge**: This refuge is a protected area that provides a safe habitat for orcas and other marine wildlife.\\n3. **Olympic National Park**: Located on the Olympic Peninsula in Washington state, this park offers orca sightings in the Pacific Ocean and surrounding waters.\\n4. **Neah Bay**: Located on the Olympic Peninsula, Neah Bay is a popular spot for orca sightings, particularly during the summer months.\\n\\nThe best time to see orcas in these locations is during the summer months (June to September), when the waters are calmer and the orcas are more active.\\n\\nKeep in mind that orca sightings are not guaranteed, as they are wild animals and their behavior can be unpredictable. However, visiting these locations during the peak season increases your chances of spotting these magnificent creatures.\\n\\nWould you like to know more about orcas or their habitats?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 273, 'prompt_tokens': 91, 'total_tokens': 364, 'completion_time': 0.405902447, 'prompt_time': 0.005368292, 'queue_time': 0.050075398, 'total_time': 0.411270739}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_c54ae48ece', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--580113a2-958d-4b55-896a-ca330b9621a8-0', usage_metadata={'input_tokens': 91, 'output_tokens': 273, 'total_tokens': 364})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model1.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37b351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best place to see Orcas (also known as killer whales) in the US is in the Pacific Northwest, particularly in the waters around Washington state and British Columbia, Canada. \\n\\nSome popular locations for orca sightings include:\\n\\n1. **Puget Sound**: Specifically, the San Juan Islands, which are located between the mainland and Vancouver Island. This area is home to the Southern Resident orcas, a distinct population of orcas that feed on salmon.\\n2. **San Juan Islands National Wildlife Refuge**: This refuge is a protected area that provides a safe habitat for orcas and other marine wildlife.\\n3. **Olympic National Park**: Located on the Olympic Peninsula in Washington state, this park offers orca sightings in the Pacific Ocean and surrounding waters.\\n4. **Neah Bay**: Located on the Olympic Peninsula, Neah Bay is a popular spot for orca sightings, particularly during the summer months.\\n\\nThe best time to see orcas in these locations is during the summer months (June to September), when the waters are calmer and the orcas are more active.\\n\\nKeep in mind that orca sightings are not guaranteed, as they are wild animals and their behavior can be unpredictable. However, visiting these locations during the peak season increases your chances of spotting these magnificent creatures.\\n\\nWould you like to know more about orcas or their habitats?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to show the content from response\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe73363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 91, 'output_tokens': 273, 'total_tokens': 364}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to show the metadata from response\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6966c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3373e2ae",
   "metadata": {},
   "source": [
    "# Adding Tools supports :-Tools are useful whenever you want a model to interact with external systems(apis,databases,internet searching..so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08460f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import  tool,Tool\n",
    "\n",
    "#now adding multiplication tool to my llm system.\n",
    "@tool\n",
    "def multiplication(a:float,b:float) -> float:\n",
    "    \"\"\"multiplying two operands with help of multipication operators\"\"\"\n",
    "    \n",
    "    return a*b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295c685b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.tools.structured.StructuredTool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1b6ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A58F5B1240>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A58F5E0280>, root_client=<openai.OpenAI object at 0x000001A58F5B19C0>, root_async_client=<openai.AsyncOpenAI object at 0x000001A5909B4F10>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiplication', 'description': 'multiplying two operands with help of multipication operators', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now binding this multiply tool with llm.\n",
    "llm_with_tool = model2.bind_tools(tools=[multiplication])\n",
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934b0e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zYWpWdex9HtLOpwpvQzemGWi', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiplication'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 60, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CGNNGnW8ZIrCEu9NVlT9FVd7612K7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--07ddac1b-bc43-4203-af09-065d466097c8-0', tool_calls=[{'name': 'multiplication', 'args': {'a': 2, 'b': 3}, 'id': 'call_zYWpWdex9HtLOpwpvQzemGWi', 'type': 'tool_call'}], usage_metadata={'input_tokens': 60, 'output_tokens': 34, 'total_tokens': 94, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = llm_with_tool.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"user\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5961902f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiplication',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_zYWpWdex9HtLOpwpvQzemGWi',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb117be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is New Delhi.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 58, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CGNNH6FphrNNWXg9n9DgWvAra2GAj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9323863d-1d5f-4f40-8f1e-ed15900865d1-0', usage_metadata={'input_tokens': 58, 'output_tokens': 9, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call2 = llm_with_tool.invoke([HumanMessage(content=f\"what is the capital of india\", name=\"user\")])\n",
    "tool_call2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc25ae6",
   "metadata": {},
   "source": [
    "### conclusion:- if i bind tool with llm then llm will decide based on user query either they have to call tool or just repond normally using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356942c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "085ef077",
   "metadata": {},
   "source": [
    "## now we gonna see how we can used tools in chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02995d99",
   "metadata": {},
   "source": [
    "### Using messages state or memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa8046ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,Annotated\n",
    "from langchain_core.messages import AnyMessage #means anykind of message it will store in this list\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages] #add_messgae is reducer will perform adding operation of msg generated by LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7097c06b",
   "metadata": {},
   "source": [
    "### example showing how add messages will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6664e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating another class that inherit the state schema class\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ae1a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='36593d38-3e4d-4642-8961-312086134c52'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='user', id='f00105c0-da81-41ca-beb6-7c4b09b71466'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='user', id='f55edb4d-1cdd-40c2-80e9-51da41888a02')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"user\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"user\")\n",
    "\n",
    "\n",
    "#testing how add messages are working.\n",
    "add_messages(initial_messages,new_message) #reqd 2 list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e46251e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e008fe6",
   "metadata": {},
   "source": [
    "# Lets create Graph that can call tools based on user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd0578d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1a590ce30a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "graph = StateGraph(state_schema=MessagesState)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c34af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state:MessagesState) ->MessagesState:\n",
    "    #fetching the message from state.\n",
    "    messages = state['messages']\n",
    "    \n",
    "    #sending this msg to llm model\n",
    "    response = llm_with_tool.invoke(messages)\n",
    "    \n",
    "    #return this response to state or updating it.\n",
    "    return {\n",
    "        \"messages\":[response] #passing entire AI content to state memory\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d881c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001A590FDA650>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START,END\n",
    "#building nodes and edges\n",
    "graph.add_node(node=\"tool_calling_llm\",action=tool_calling_llm)\n",
    "\n",
    "#adding edges to graph.\n",
    "graph.add_edge(START,\"tool_calling_llm\")\n",
    "graph.add_edge('tool_calling_llm',END)\n",
    "\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e9b1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#worklfow.\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "135d519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello!', additional_kwargs={}, response_metadata={}, id='89894a70-24c7-4d6c-8ac9-95a14991652e'),\n",
       "  AIMessage(content='Hi there! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 53, 'total_tokens': 64, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CGNNIy8QXsVSUCSqg93SGlB7TwTjZ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dc26095f-3a5c-4bbc-91b6-2cb33caf2f61-0', usage_metadata={'input_tokens': 53, 'output_tokens': 11, 'total_tokens': 64, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = workflow.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d9a3cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12879b",
   "metadata": {},
   "source": [
    "## how automatically llm will call tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8334e882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiplication (call_tYKx4KpQrInV1kr3zHYJ1N4m)\n",
      " Call ID: call_tYKx4KpQrInV1kr3zHYJ1N4m\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = workflow.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76ee75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe5eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8309e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb679ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c98f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daca5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
